{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import geohash2\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "from io import StringIO\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats._result_classes import PearsonRResult\n",
    "from scipy.stats import NearConstantInputWarning, ConstantInputWarning\n",
    "from requests import Response\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Explicitly providing path to '.env'\n",
    "from pathlib import Path  # Python 3.6+ only\n",
    "# Load .env variables\n",
    "_ = load_dotenv(dotenv_path=f\"{Path().resolve().parents[1]}/standalone/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_timestamp(datetime_iso8601: str) -> int:\n",
    "    \"\"\"\n",
    "    Datetime ISO 8601 Format to Timestamp\n",
    "    TZ='America/Bogota' -05:00\n",
    "\n",
    "    :params\n",
    "    :datetime_iso8601: str, Datetime ISO 8601 Format\n",
    "\n",
    "    :return: int, Timestamp\n",
    "\n",
    "    :example\n",
    "        - to_timestamp('2023-03-17T00:00:00-05:00')\n",
    "            return: 1679029200000\n",
    "    \"\"\"\n",
    "    return int(datetime.fromisoformat(datetime_iso8601).timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_influxdb(sql_query: str) -> Response:\n",
    "    \"\"\"\n",
    "    Request to InfluxDB API REST\n",
    "\n",
    "    :params\n",
    "    :sql_query: str, InfluxDB SQL query\n",
    "\n",
    "    :return: Response, InfluxDB response as CSV text\n",
    "    \"\"\"\n",
    "    endpoint = os.getenv(\"URL_INFLUXDB_QUERY_ENDPOINT\", None)\n",
    "    database = os.getenv(\"DB_NAME_INFLUXDB\", None)\n",
    "    parameters = {\n",
    "        'db': database,\n",
    "        'q': sql_query,\n",
    "        'epoch': 'ms'\n",
    "    }\n",
    "    # To get response as CSV text\n",
    "    headers = {'Accept': 'application/csv'}\n",
    "    # GET Request\n",
    "    return requests.get(endpoint, params=parameters, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tangaras(start_timestamp: int, end_timestamp: int) -> str:\n",
    "    \"\"\"\n",
    "    Get InfluxDB SQL query of all Tangara sensors that have reported data over a period of time.\n",
    "\n",
    "    :params:\n",
    "    :start_timestamp: int, timestamp datetime value, ms\n",
    "    :end_timestamp: int, timestamp datetime value, ms\n",
    "\n",
    "    :return: str, InfluxDB SQL Query\n",
    "    \"\"\"\n",
    "    # Period DateTime\n",
    "    period_time = f\"time >= {start_timestamp}ms AND time <= {end_timestamp}ms\"\n",
    "    # SQL\n",
    "    sql_query = \"SELECT DISTINCT(geo) AS \\\"geohash\\\" \"\\\n",
    "                \"FROM \\\"fixed_stations_01\\\" WHERE \"\\\n",
    "                \"(\\\"geo3\\\" = 'd29') AND \"\\\n",
    "                f\"{period_time} \"\\\n",
    "                \"GROUP BY \\\"name\\\";\"\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_measure(mac_tangaras: [str], start_timestamp: int, end_timestamp: int, measure: str='pm25') -> str:\n",
    "    \"\"\"\n",
    "    Get InfluxDB SQL query for specific measure (datatype) and for each Tangara sensor identified by MAC address between a period of time.\n",
    "\n",
    "    :params:\n",
    "    :mac_tangaras: [str], Tangara sensor MAC address\n",
    "    :start_timestamp: int, timestamp datetime value, ms\n",
    "    :end_timestamp: int, timestamp datetime value, ms\n",
    "    :measure: str, choice ['pm25', 'tmp', 'hum']\n",
    "\n",
    "    :return: str, InfluxDB SQL Query\n",
    "    \"\"\"\n",
    "    # Period DateTime\n",
    "    period_time = f\"time >= {start_timestamp}ms AND time <= {end_timestamp}ms\"\n",
    "    # SQL Datatype by Tangara Sensor\n",
    "    sql_query = \"\"\n",
    "    for mac in mac_tangaras:\n",
    "        sql_query += f\"SELECT \\\"name\\\", last(\\\"{measure}\\\") \"\\\n",
    "                    \"FROM \\\"fixed_stations_01\\\" WHERE \"\\\n",
    "                    f\"(\\\"name\\\" = '{mac}') AND \"\\\n",
    "                    f\"{period_time} \" \\\n",
    "                    \"GROUP BY time(30s) fill(none); \"\n",
    "    return sql_query[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_be_checked(df_sensor: DataFrame, threshold_data_percent: int=80) -> [bool, int, int]:\n",
    "    \"\"\"\n",
    "    Check if the sensor must be checked, because it has not reported enough data.\n",
    "    Return [bool, int]: [{Does it to be checked?}, {Total data}, {Total missing data}]\n",
    "\n",
    "    :params:\n",
    "    :df_sensor: DataFrame, Data reported by Tangara sensor\n",
    "    :threshold_data_percent: int, Threshold to check enough data reported\n",
    "\n",
    "    :return: [bool, int, int], Does it not report enough data?\n",
    "    \"\"\"\n",
    "    # Check missing data\n",
    "    total = df_sensor.shape[0]\n",
    "    missing_data_percent = round(df_sensor.isna().sum()[0] * 100 / total)\n",
    "    data_percent = round(df_sensor.count()[0] * 100 / total)\n",
    "    # Threshold\n",
    "    if data_percent < threshold_data_percent:\n",
    "        # to be checked\n",
    "        return [False, data_percent, missing_data_percent]\n",
    "    # OK\n",
    "    return [True, data_percent, missing_data_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_corr_ok(df_reference_sensor: DataFrame, df_target_sensor: DataFrame, threshold_corr: float=0.9) -> [bool, float]:\n",
    "    \"\"\"\n",
    "    Check if the target sensor must be checked, because it has not reference with the reference sensor.\n",
    "    Return [bool, float]: [{Is correlation ok?}, {Correlation percent}]\n",
    "\n",
    "    corr = 0, No correlation\n",
    "    corr = [-1, 0), Negative correlation\n",
    "    corr = (0, 1], Positive correlation\n",
    "\n",
    "    :params:\n",
    "    :df_reference_sensor: DataFrame, Reference Tangara sensor\n",
    "    :df_target_sensor: DataFrame, Target Tangara sensor\n",
    "    :threshold_corr: float, Threshold to check the positive correlation percent between both Tangara sensors\n",
    "\n",
    "    :return: [bool, float], There is not a correlation?\n",
    "    \"\"\"\n",
    "    # Pearson Correlation Coefficient\n",
    "    corr = 0\n",
    "    warnings.simplefilter(\"ignore\", category=NearConstantInputWarning)\n",
    "    warnings.simplefilter(\"ignore\", category=ConstantInputWarning)\n",
    "    if (not df_reference_sensor.hasnans and not df_target_sensor.hasnans) and (df_reference_sensor.shape[0] == df_target_sensor.shape[0]):\n",
    "        corr, _ = pearsonr(df_reference_sensor, df_target_sensor) if df_target_sensor.std() != 0 else PearsonRResult(0,0,alternative=0,n=0)\n",
    "        corr = 0 if math.isnan(corr) else corr\n",
    "        \n",
    "    # corr = 0, No correlation\n",
    "    # corr = [-1, 0), Negative correlation\n",
    "    # corr = (0, 1], Positive correlation\n",
    "    # Threshold\n",
    "    if corr < threshold_corr:\n",
    "        # There is not correlation\n",
    "        return [False, float(\"{:.2f}\".format(corr))]\n",
    "    # There is correlation\n",
    "    return [True, float(\"{:.2f}\".format(corr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df: DataFrame, filename: str, datafolder: str='0_raw') -> None:\n",
    "    \"\"\"\n",
    "    Save DataFrame into data folder as a CSV file.\n",
    "    datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "\n",
    "    :params:\n",
    "    :df: DataFrame, pandas DataFrame\n",
    "    :filename: str, CSV file name with extension .csv\n",
    "    :datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "    \"\"\"\n",
    "    # Save DataFrame into CSV file\n",
    "    path_datafolder=f\"{Path().resolve().parents[1]}/standalone/data/{datafolder}\"\n",
    "    df.to_csv(f\"{path_datafolder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_csv(filename: str, datafolder: str='0_raw') -> DataFrame:\n",
    "    \"\"\"\n",
    "    Load DataFrame from CSV file localted in data folder.\n",
    "    datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "\n",
    "    :params:\n",
    "    :filename: str, CSV file name with extension .csv\n",
    "    :datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "\n",
    "    :return: df: DataFrame, pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Load DataFrame from CSV file\n",
    "    path_csvfile=f\"{Path().resolve().parents[1]}/standalone/data/{datafolder}/{filename}\"\n",
    "    return pd.read_csv(path_csvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_tangara_sensors(start_timestamp: int, end_timestamp: int) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get Data Frame Tangaras Sensors of all Tangara sensors that have reported data over a period of time.\n",
    "\n",
    "    :params:\n",
    "    :start_timestamp: int, timestamp datetime value, ms\n",
    "    :end_timestamp: int, timestamp datetime value, ms\n",
    "\n",
    "    :return: DataFrame, Tangaras Sensors\n",
    "    \"\"\"\n",
    "    # Query Tangaras\n",
    "    influxdb_sql_query_tangaras = query_tangaras(start_timestamp, end_timestamp)\n",
    "    # InfluxDB API REST Request\n",
    "    influxdb_request = request_influxdb(influxdb_sql_query_tangaras)\n",
    "    #print(influxdb_request)\n",
    "    #print(influxdb_request.text)\n",
    "\n",
    "    # Data Frame Tangaras\n",
    "    df_tangaras = pd.read_csv(StringIO(influxdb_request.text), sep=\",\")\n",
    "\n",
    "    # Remove/Add Columns\n",
    "    df_tangaras = df_tangaras[['tags', 'geohash']]\n",
    "    df_tangaras['MAC'] = df_tangaras['tags'].apply(lambda x: x.split('=')[1])\n",
    "    df_tangaras['GEOLOCATION'] = df_tangaras['geohash'].apply(lambda x: \" \".join(str(value) for value in list(geohash2.decode_exactly(x)[0:2])))\n",
    "    df_tangaras['LATITUDE'] = df_tangaras['GEOLOCATION'].apply(lambda x: x.split(' ')[0])\n",
    "    df_tangaras['LONGITUDE'] = df_tangaras['GEOLOCATION'].apply(lambda x: x.split(' ')[1])\n",
    "    df_tangaras['tags'] = df_tangaras['tags'].apply(lambda x: f\"TANGARA_{x[-4:]}\")\n",
    "    df_tangaras.rename(columns={'tags': 'ID', 'geohash': 'GEOHASH'}, inplace=True)\n",
    "    \n",
    "    # Date time when query is executed\n",
    "    #tz = timezone(timedelta(hours=-5))\n",
    "    #df_tangaras['DATETIME'] = datetime.now(tz=tz)\n",
    "\n",
    "    # Set Index\n",
    "    df_tangaras.set_index('ID', inplace=True)\n",
    "    \n",
    "    return df_tangaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_data_sensors(df_tangaras: DataFrame, start_timestamp: int, end_timestamp: int, measure: str='pm25') -> DataFrame:\n",
    "    \"\"\"\n",
    "    Get Measure Data Frame Sensors of all Tangara sensors that have reported data over a period of time.\n",
    "    \n",
    "    :params:\n",
    "    :df_tangaras: DataFrame, Tangaras DataFrame\n",
    "    :start_timestamp: int, timestamp datetime value, ms\n",
    "    :end_timestamp: int, timestamp datetime value, ms\n",
    "    :measure: str, choice ['pm25', 'tmp', 'hum']\n",
    "\n",
    "    :return: DataFrame, Measure Data Frame Sensors\n",
    "    \"\"\"\n",
    "    # Data Frame Sensors List\n",
    "    df_sensors_list: [DataFrame] = []\n",
    "    # SQL Query Data Sensors\n",
    "    influxdb_sql_query_measure = query_measure(df_tangaras['MAC'].to_list(), start_timestamp, end_timestamp, measure)\n",
    "    # InfluxDB API REST Request\n",
    "    influxdb_request = request_influxdb(influxdb_sql_query_measure)\n",
    "    #print(influxdb_request)\n",
    "    #print(influxdb_request.text)\n",
    "\n",
    "    # Data Frame InfluxDB Sensors\n",
    "    df_influxdb_sensors = pd.read_csv(StringIO(influxdb_request.text), sep=\",\", low_memory=False)\n",
    "\n",
    "    # Data Measure\n",
    "    MEASURE = {'pm25': 'PM2.5', 'tmp': 'TEMP', 'hum': 'HUM'}[measure]\n",
    "\n",
    "    # Remove/Add Columns\n",
    "    df_influxdb_sensors = df_influxdb_sensors[['time', 'name.1', 'last']]\n",
    "    df_influxdb_sensors.rename(columns={'time': 'DATETIME', 'name.1': 'MAC', 'last': MEASURE}, inplace=True)\n",
    "\n",
    "    # Truncate Response\n",
    "    for _, row in df_tangaras.iterrows():\n",
    "        df_sensor = df_influxdb_sensors.loc[df_influxdb_sensors['MAC'] == row['MAC']].reset_index(drop=True)[['DATETIME', MEASURE]] # Warning\n",
    "        if not df_sensor.empty:\n",
    "            df_sensor.rename(columns={MEASURE: row['ID']}, inplace=True)\n",
    "            df_sensor.set_index('DATETIME', inplace=True)\n",
    "            df_sensors_list.append(df_sensor)\n",
    "    \n",
    "    df_sensors = df_sensors_list[0].join(df_sensors_list[1:]).reset_index()\n",
    "\n",
    "    # Date Time ISO 8601 Format, TZ='America/Bogota' -05:00\n",
    "    tz = timezone(timedelta(hours=-5))\n",
    "    df_sensors['DATETIME'] = df_sensors['DATETIME'].apply(lambda x: datetime.fromtimestamp(int(x) / 1000, tz=tz).isoformat())\n",
    "    df_sensors['DATETIME'] = pd.to_datetime(df_sensors['DATETIME'])\n",
    "\n",
    "    # Set Index\n",
    "    df_sensors.set_index('DATETIME', inplace=True)\n",
    "    df_sensors = df_sensors.asfreq(freq='30S')\n",
    "\n",
    "    df_sensors[df_sensors.columns.to_list()] = df_sensors[df_sensors.columns.to_list()].astype('float64')\n",
    "    \n",
    "    return df_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
