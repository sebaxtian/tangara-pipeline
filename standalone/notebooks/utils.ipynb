{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from pandas import DataFrame\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats._result_classes import PearsonRResult\n",
    "from requests import Response\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Explicitly providing path to '.env'\n",
    "from pathlib import Path  # Python 3.6+ only\n",
    "# Load .env variables\n",
    "_ = load_dotenv(dotenv_path=f\"{Path().resolve().parents[1]}/standalone/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_timestamp(datetime_iso8601: str) -> int:\n",
    "    \"\"\"\n",
    "    Datetime ISO 8601 Format to Timestamp\n",
    "    TZ='America/Bogota' -05:00\n",
    "\n",
    "    :params\n",
    "    :datetime_iso8601: str, Datetime ISO 8601 Format\n",
    "\n",
    "    :return: int, Timestamp\n",
    "\n",
    "    :example\n",
    "        - to_timestamp('2023-03-17T00:00:00-05:00')\n",
    "            return: 1679029200000\n",
    "    \"\"\"\n",
    "    return int(datetime.fromisoformat(datetime_iso8601).timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_influxdb(sql_query: str) -> Response:\n",
    "    \"\"\"\n",
    "    Request to InfluxDB API REST\n",
    "\n",
    "    :params\n",
    "    :sql_query: str, InfluxDB SQL query\n",
    "\n",
    "    :return: Response, InfluxDB response as CSV text\n",
    "    \"\"\"\n",
    "    endpoint = os.getenv(\"URL_INFLUXDB_QUERY_ENDPOINT\", None)\n",
    "    database = os.getenv(\"DB_NAME_INFLUXDB\", None)\n",
    "    parameters = {\n",
    "        'db': database,\n",
    "        'q': sql_query,\n",
    "        'epoch': 'ms'\n",
    "    }\n",
    "    # To get response as CSV text\n",
    "    headers = {'Accept': 'application/csv'}\n",
    "    # GET Request\n",
    "    return requests.get(endpoint, params=parameters, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tangaras(start_timestamp: int, end_timestamp: int) -> str:\n",
    "    \"\"\"\n",
    "    Get InfluxDB SQL query of all Tangara sensors that have reported data over a period of time.\n",
    "\n",
    "    :params:\n",
    "    :start_timestamp: int, timestamp datetime value, ms\n",
    "    :end_timestamp: int, timestamp datetime value, ms\n",
    "\n",
    "    :return: str, InfluxDB SQL Query\n",
    "    \"\"\"\n",
    "    # Period DateTime\n",
    "    period_time = f\"time >= {start_timestamp}ms AND time <= {end_timestamp}ms\"\n",
    "    # SQL\n",
    "    sql_query = \"SELECT DISTINCT(geo) AS \\\"geohash\\\" \"\\\n",
    "                \"FROM \\\"fixed_stations_01\\\" WHERE \"\\\n",
    "                \"(\\\"geo3\\\" = 'd29') AND \"\\\n",
    "                f\"{period_time} \"\\\n",
    "                \"GROUP BY \\\"name\\\";\"\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_measure(mac_tangaras: [str], start_timestamp: int, end_timestamp: int, datatype: str='pm25') -> str:\n",
    "    \"\"\"\n",
    "    Get InfluxDB SQL query for specific measure (datatype) and for each Tangara sensor identified by MAC address between a period of time.\n",
    "\n",
    "    :params:\n",
    "    :mac_tangaras: [str], Tangara sensor MAC address\n",
    "    :start_timestamp: int, timestamp datetime value, ms\n",
    "    :end_timestamp: int, timestamp datetime value, ms\n",
    "    :datatype: str, choice ['pm25', 'tmp', 'hum']\n",
    "\n",
    "    :return: str, InfluxDB SQL Query\n",
    "    \"\"\"\n",
    "    # Period DateTime\n",
    "    period_time = f\"time >= {start_timestamp}ms AND time <= {end_timestamp}ms\"\n",
    "    # SQL Datatype by Tangara Sensor\n",
    "    sql_query = \"\"\n",
    "    for mac in mac_tangaras:\n",
    "        sql_query += f\"SELECT \\\"name\\\", last(\\\"{datatype}\\\") \"\\\n",
    "                    \"FROM \\\"fixed_stations_01\\\" WHERE \"\\\n",
    "                    f\"(\\\"name\\\" = '{mac}') AND \"\\\n",
    "                    f\"{period_time} \" \\\n",
    "                    \"GROUP BY time(30s) fill(none); \"\n",
    "    return sql_query[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_be_checked(df_sensor: DataFrame, threshold_data_percent: int=80) -> [bool, int, int]:\n",
    "    \"\"\"\n",
    "    Check if the sensor must be checked, because it has not reported enough data.\n",
    "    Return [bool, int]: [{Does it to be checked?}, {Total data}, {Total missing data}]\n",
    "\n",
    "    :params:\n",
    "    :df_sensor: DataFrame, Data reported by Tangara sensor\n",
    "    :threshold_data_percent: int, Threshold to check enough data reported\n",
    "\n",
    "    :return: [bool, int, int], Does it not report enough data?\n",
    "    \"\"\"\n",
    "    # Check missing data\n",
    "    total = df_sensor.shape[0]\n",
    "    missing_data_percent = round(df_sensor.isna().sum()[0] * 100 / total)\n",
    "    data_percent = round(df_sensor.count()[0] * 100 / total)\n",
    "    # Threshold\n",
    "    if data_percent < threshold_data_percent:\n",
    "        # to be checked\n",
    "        return [False, data_percent, missing_data_percent]\n",
    "    # OK\n",
    "    return [True, data_percent, missing_data_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_corr_ok(df_reference_sensor: DataFrame, df_target_sensor: DataFrame, threshold_corr: float=0.9) -> [bool, float]:\n",
    "    \"\"\"\n",
    "    Check if the target sensor must be checked, because it has not reference with the reference sensor.\n",
    "    Return [bool, float]: [{Is correlation ok?}, {Correlation percent}]\n",
    "\n",
    "    corr = 0, No correlation\n",
    "    corr = [-1, 0), Negative correlation\n",
    "    corr = (0, 1], Positive correlation\n",
    "\n",
    "    :params:\n",
    "    :df_reference_sensor: DataFrame, Reference Tangara sensor\n",
    "    :df_target_sensor: DataFrame, Target Tangara sensor\n",
    "    :threshold_corr: float, Threshold to check the positive correlation percent between both Tangara sensors\n",
    "\n",
    "    :return: [bool, float], There is not a correlation?\n",
    "    \"\"\"\n",
    "    # Pearson Correlation Coefficient\n",
    "    corr = 0\n",
    "    if (not df_reference_sensor.hasnans and not df_target_sensor.hasnans) and (df_reference_sensor.shape[0] == df_target_sensor.shape[0]):\n",
    "        corr, _ = pearsonr(df_reference_sensor, df_target_sensor) if df_target_sensor.std() != 0 else PearsonRResult(0,0,alternative=0,n=0)\n",
    "        corr = 0 if math.isnan(corr) else corr\n",
    "    # corr = 0, No correlation\n",
    "    # corr = [-1, 0), Negative correlation\n",
    "    # corr = (0, 1], Positive correlation\n",
    "    # Threshold\n",
    "    if corr < threshold_corr:\n",
    "        # There is not correlation\n",
    "        return [False, float(\"{:.2f}\".format(corr))]\n",
    "    # There is correlation\n",
    "    return [True, float(\"{:.2f}\".format(corr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df: DataFrame, filename: str, datafolder: str='0_raw') -> None:\n",
    "    \"\"\"\n",
    "    Save DataFrame into data folder as a CSV file.\n",
    "    datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "\n",
    "    :params:\n",
    "    :df: DataFrame, pandas DataFrame\n",
    "    :filename: str, CSV file name with extension .csv\n",
    "    :datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "    \"\"\"\n",
    "    # Save DataFrame into CSV file\n",
    "    path_datafolder=f\"{Path().resolve().parents[1]}/standalone/data/{datafolder}\"\n",
    "    df.to_csv(f\"{path_datafolder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_csv(filename: str, datafolder: str='0_raw') -> DataFrame:\n",
    "    \"\"\"\n",
    "    Load DataFrame from CSV file localted in data folder.\n",
    "    datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "\n",
    "    :params:\n",
    "    :filename: str, CSV file name with extension .csv\n",
    "    :datafolder: str, choice ['0_raw', '1_clean', '2_features', 'backup']\n",
    "\n",
    "    :return: df: DataFrame, pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Load DataFrame from CSV file\n",
    "    path_csvfile=f\"{Path().resolve().parents[1]}/standalone/data/{datafolder}/{filename}\"\n",
    "    return pd.read_csv(path_csvfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
