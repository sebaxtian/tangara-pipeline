{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from kedro.config import ConfigLoader\n",
    "from kedro.framework.project import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-29 19:02:58,579 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...\n",
      "Parameters: {'influxdb_version': '2.x', 'nowcast_datetime': '2022-09-15T00:00:00-05:00', 'start_datetime': None}\n",
      "Credentials: {'influxdb': {'url': 'http://localhost:8086', 'token': 'MsA2XntxWt2s22EXoy1DVpjmHzS14z_3U8ucm1vn8EAkccf4wxGQxbvFi6JrOCTN_50ez0npAUa52EE1wAZFJA==', 'org': 'Tangara', 'bucket': 'Tangara', 'username': 'tangara', 'password': 'sebaxtian', 'database': 'Tangara'}}\n"
     ]
    }
   ],
   "source": [
    "# Load Parameters\n",
    "parameters = catalog.load('parameters')\n",
    "\n",
    "# Load Credentials\n",
    "conf_path = str(context.project_path / settings.CONF_SOURCE)\n",
    "conf_loader = ConfigLoader(conf_source=conf_path, env='local')\n",
    "credentials = conf_loader.get('credentials*', 'credentials*/**')\n",
    "\n",
    "print('Parameters:', parameters)\n",
    "print('Credentials:', credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-29 19:02:58,683 - kedro.io.data_catalog - INFO - Loading data from `pm25_clean` (CSVDataSet)...\n",
      "2022-09-29 19:02:58,697 - kedro.io.data_catalog - INFO - Loading data from `temp_raw` (CSVDataSet)...\n",
      "2022-09-29 19:02:58,710 - kedro.io.data_catalog - INFO - Loading data from `hum_raw` (CSVDataSet)...\n",
      "2022-09-29 19:02:58,718 - kedro.io.data_catalog - INFO - Loading data from `co2_raw` (CSVDataSet)...\n",
      "2022-09-29 19:02:58,728 - kedro.io.data_catalog - INFO - Loading data from `aqi_instant` (CSVDataSet)...\n",
      "2022-09-29 19:02:58,737 - kedro.io.data_catalog - INFO - Loading data from `tangara_stations` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "# Kedro Catalog\n",
    "pm25_clean = catalog.load('pm25_clean')\n",
    "temp_raw = catalog.load('temp_raw')\n",
    "hum_raw = catalog.load('hum_raw')\n",
    "co2_raw = catalog.load('co2_raw')\n",
    "aqi_instant = catalog.load('aqi_instant')\n",
    "tangara_stations = catalog.load('tangara_stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>ID</th>\n",
       "      <th>MAC</th>\n",
       "      <th>GEOHASH</th>\n",
       "      <th>GEOREGION</th>\n",
       "      <th>GEOLOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-29T19:00:48.971171-05:00</td>\n",
       "      <td>TANGARA_2BBA</td>\n",
       "      <td>D29ESP32DE02BBA</td>\n",
       "      <td>d29e6b4</td>\n",
       "      <td>d29</td>\n",
       "      <td>3.38447571 -76.51634216</td>\n",
       "      <td>3.384476</td>\n",
       "      <td>-76.516342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-29T19:00:48.971171-05:00</td>\n",
       "      <td>TANGARA_14D6</td>\n",
       "      <td>D29ESP32DED14D6</td>\n",
       "      <td>d29dfx4</td>\n",
       "      <td>d29</td>\n",
       "      <td>3.33503723 -76.52732849</td>\n",
       "      <td>3.335037</td>\n",
       "      <td>-76.527328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-29T19:00:48.971171-05:00</td>\n",
       "      <td>TANGARA_1CE2</td>\n",
       "      <td>D29ESP32DED1CE2</td>\n",
       "      <td>d29e4cv</td>\n",
       "      <td>d29</td>\n",
       "      <td>3.35014343 -76.51222229</td>\n",
       "      <td>3.350143</td>\n",
       "      <td>-76.512222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-29T19:00:48.971171-05:00</td>\n",
       "      <td>TANGARA_2492</td>\n",
       "      <td>D29ESP32DED2492</td>\n",
       "      <td>d29e64g</td>\n",
       "      <td>d29</td>\n",
       "      <td>3.39958191 -76.54792786</td>\n",
       "      <td>3.399582</td>\n",
       "      <td>-76.547928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-29T19:00:48.971171-05:00</td>\n",
       "      <td>TANGARA_2FF6</td>\n",
       "      <td>D29ESP32DED2FF6</td>\n",
       "      <td>d29e66v</td>\n",
       "      <td>d29</td>\n",
       "      <td>3.39958191 -76.53419495</td>\n",
       "      <td>3.399582</td>\n",
       "      <td>-76.534195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           DATETIME            ID              MAC  GEOHASH  \\\n",
       "0  2022-09-29T19:00:48.971171-05:00  TANGARA_2BBA  D29ESP32DE02BBA  d29e6b4   \n",
       "1  2022-09-29T19:00:48.971171-05:00  TANGARA_14D6  D29ESP32DED14D6  d29dfx4   \n",
       "2  2022-09-29T19:00:48.971171-05:00  TANGARA_1CE2  D29ESP32DED1CE2  d29e4cv   \n",
       "3  2022-09-29T19:00:48.971171-05:00  TANGARA_2492  D29ESP32DED2492  d29e64g   \n",
       "4  2022-09-29T19:00:48.971171-05:00  TANGARA_2FF6  D29ESP32DED2FF6  d29e66v   \n",
       "\n",
       "  GEOREGION              GEOLOCATION  LATITUDE  LONGITUDE  \n",
       "0       d29  3.38447571 -76.51634216  3.384476 -76.516342  \n",
       "1       d29  3.33503723 -76.52732849  3.335037 -76.527328  \n",
       "2       d29  3.35014343 -76.51222229  3.350143 -76.512222  \n",
       "3       d29  3.39958191 -76.54792786  3.399582 -76.547928  \n",
       "4       d29  3.39958191 -76.53419495  3.399582 -76.534195  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tangara_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>TANGARA_2BBA</th>\n",
       "      <th>TANGARA_14D6</th>\n",
       "      <th>TANGARA_1CE2</th>\n",
       "      <th>TANGARA_2492</th>\n",
       "      <th>TANGARA_2FF6</th>\n",
       "      <th>TANGARA_48C6</th>\n",
       "      <th>TANGARA_4D7A</th>\n",
       "      <th>TANGARA_532E</th>\n",
       "      <th>TANGARA_EA06</th>\n",
       "      <th>TANGARA_F1AE</th>\n",
       "      <th>TANGARA_FAC6</th>\n",
       "      <th>TANGARA_06BE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-28T19:00:30-05:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-28T19:01:00-05:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-28T19:01:30-05:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-28T19:02:00-05:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-28T19:02:30-05:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DATETIME  TANGARA_2BBA  TANGARA_14D6  TANGARA_1CE2  \\\n",
       "0  2022-09-28T19:00:30-05:00          10.0           NaN           NaN   \n",
       "1  2022-09-28T19:01:00-05:00          10.0           9.0           9.0   \n",
       "2  2022-09-28T19:01:30-05:00          10.0           9.0           9.0   \n",
       "3  2022-09-28T19:02:00-05:00           9.0          10.0          10.0   \n",
       "4  2022-09-28T19:02:30-05:00          11.0           9.0          10.0   \n",
       "\n",
       "   TANGARA_2492  TANGARA_2FF6  TANGARA_48C6  TANGARA_4D7A  TANGARA_532E  \\\n",
       "0           7.0           NaN           NaN           NaN           0.0   \n",
       "1           6.0          10.0           2.0           0.0           0.0   \n",
       "2           7.0          11.0           2.0           0.0           0.0   \n",
       "3           6.0          11.0           1.0           0.0           0.0   \n",
       "4           7.0          11.0           2.0           0.0           1.0   \n",
       "\n",
       "   TANGARA_EA06  TANGARA_F1AE  TANGARA_FAC6  TANGARA_06BE  \n",
       "0           0.0           NaN           NaN           NaN  \n",
       "1           0.0           3.0           NaN          12.0  \n",
       "2           0.0           3.0           NaN          12.0  \n",
       "3           0.0           3.0           NaN          13.0  \n",
       "4           0.0           3.0           NaN          13.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Tangara Stations Measurements Dictionary\n",
    "def get_stations_measurements(stations, pm25, aqi, temp, hum, co2):\n",
    "    # Tangara Stations Measurements Dictionary\n",
    "    stations_measurements = {}\n",
    "    # For each Tangara Station\n",
    "    for station in stations.itertuples():\n",
    "        #print(station._fields)\n",
    "        #print(getattr(station, 'ID'))\n",
    "        station_id = getattr(station, 'ID')\n",
    "        #print('station_id:', station_id)\n",
    "\n",
    "        # Set Index\n",
    "        station_pm25 = pm25[['DATETIME', station_id]].set_index('DATETIME')\n",
    "        station_aqi = aqi[['DATETIME', station_id]].set_index('DATETIME')\n",
    "        station_temp = temp[['DATETIME', station_id]].set_index('DATETIME')\n",
    "        station_hum = hum[['DATETIME', station_id]].set_index('DATETIME')\n",
    "        station_co2 = co2[['DATETIME', station_id]].set_index('DATETIME')\n",
    "        \n",
    "        # Join Measurements\n",
    "        pm25_aqi = station_pm25.join(station_aqi, lsuffix='_PM25', rsuffix='_AQI')\n",
    "        temp_hum = station_temp.join(station_hum, lsuffix='_TEMP', rsuffix='_HUM')\n",
    "        station_measurements = pm25_aqi.join([temp_hum, station_co2])\n",
    "        \n",
    "        # Rename Columns\n",
    "        station_measurements.rename(\n",
    "            columns={\n",
    "                f'{station_id}_PM25': 'PM25',\n",
    "                f'{station_id}_AQI': 'AQI',\n",
    "                f'{station_id}_TEMP': 'TEMP',\n",
    "                f'{station_id}_HUM': 'HUM',\n",
    "                f'{station_id}': 'CO2'\n",
    "            },\n",
    "            inplace=True\n",
    "        )\n",
    "        # Reset Index\n",
    "        station_measurements = station_measurements.reset_index()\n",
    "\n",
    "        #print('station_measurements:', station_measurements.columns.to_list())\n",
    "        \n",
    "        # Add ID, MAC and GEOHASH columns\n",
    "        station_measurements['STATION_ID'] = station_id\n",
    "        station_measurements['MAC'] = getattr(station, 'MAC')\n",
    "        station_measurements['GEOHASH'] = getattr(station, 'GEOHASH')\n",
    "        station_measurements['GEOREGION'] = getattr(station, 'GEOREGION')\n",
    "\n",
    "        # Set Data Types\n",
    "        station_measurements['PM25'] = station_measurements['PM25'].astype('float64')\n",
    "        station_measurements['PM25'] = station_measurements['PM25'].apply(lambda x: x if math.isnan(x) else round(x, 0))\n",
    "        #station_measurements['AQI'] = station_measurements['AQI'].apply(lambda x: x if math.isnan(x) else math.ceil(x))\n",
    "        station_measurements['AQI'] = station_measurements['AQI'].astype('float64')\n",
    "        station_measurements['AQI'] = station_measurements['AQI'].apply(lambda x: x if math.isnan(x) else round(x, 0))\n",
    "        #station_measurements['AQI'] = station_measurements['AQI'].interpolate(method='pad', limit_direction='forward')\n",
    "        station_measurements['TEMP'] = station_measurements['TEMP'].astype('float64')\n",
    "        station_measurements['TEMP'] = station_measurements['TEMP'].apply(lambda x: x if math.isnan(x) else round(x, 0))\n",
    "        station_measurements['HUM'] = station_measurements['HUM'].astype('float64')\n",
    "        station_measurements['HUM'] = station_measurements['HUM'].apply(lambda x: x if math.isnan(x) else round(x, 0))\n",
    "        station_measurements['CO2'] = station_measurements['CO2'].astype('float64')\n",
    "        station_measurements['CO2'] = station_measurements['CO2'].apply(lambda x: x if math.isnan(x) else round(x, 0))\n",
    "\n",
    "        # Set Tangara Station Measurements\n",
    "        stations_measurements[station_id] = station_measurements\n",
    "    \n",
    "    return stations_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>PM25</th>\n",
       "      <th>AQI</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HUM</th>\n",
       "      <th>CO2</th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>MAC</th>\n",
       "      <th>GEOHASH</th>\n",
       "      <th>GEOREGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-28T19:00:30-05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TANGARA_F1AE</td>\n",
       "      <td>D29TTGOTD8F1AE</td>\n",
       "      <td>d29eg66</td>\n",
       "      <td>d29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-28T19:01:00-05:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>TANGARA_F1AE</td>\n",
       "      <td>D29TTGOTD8F1AE</td>\n",
       "      <td>d29eg66</td>\n",
       "      <td>d29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-28T19:01:30-05:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>TANGARA_F1AE</td>\n",
       "      <td>D29TTGOTD8F1AE</td>\n",
       "      <td>d29eg66</td>\n",
       "      <td>d29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-28T19:02:00-05:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>TANGARA_F1AE</td>\n",
       "      <td>D29TTGOTD8F1AE</td>\n",
       "      <td>d29eg66</td>\n",
       "      <td>d29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-28T19:02:30-05:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>TANGARA_F1AE</td>\n",
       "      <td>D29TTGOTD8F1AE</td>\n",
       "      <td>d29eg66</td>\n",
       "      <td>d29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DATETIME  PM25   AQI  TEMP   HUM    CO2    STATION_ID  \\\n",
       "0  2022-09-28T19:00:30-05:00   NaN   NaN   NaN   NaN    NaN  TANGARA_F1AE   \n",
       "1  2022-09-28T19:01:00-05:00   3.0  13.0  30.0  48.0  419.0  TANGARA_F1AE   \n",
       "2  2022-09-28T19:01:30-05:00   3.0  13.0  30.0  48.0  417.0  TANGARA_F1AE   \n",
       "3  2022-09-28T19:02:00-05:00   3.0  13.0  30.0  48.0  419.0  TANGARA_F1AE   \n",
       "4  2022-09-28T19:02:30-05:00   3.0  13.0  30.0  48.0  420.0  TANGARA_F1AE   \n",
       "\n",
       "              MAC  GEOHASH GEOREGION  \n",
       "0  D29TTGOTD8F1AE  d29eg66       d29  \n",
       "1  D29TTGOTD8F1AE  d29eg66       d29  \n",
       "2  D29TTGOTD8F1AE  d29eg66       d29  \n",
       "3  D29TTGOTD8F1AE  d29eg66       d29  \n",
       "4  D29TTGOTD8F1AE  d29eg66       d29  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_measurements = get_stations_measurements(tangara_stations, pm25_clean, aqi_instant, temp_raw, hum_raw, co2_raw)\n",
    "stations_measurements['TANGARA_F1AE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each Tangara Stations Measurements\n",
    "for station_measurements in stations_measurements.values():\n",
    "    #print(station_measurement.columns.to_list())\n",
    "    # For each station_measurement tuple\n",
    "    for row in station_measurements.itertuples():\n",
    "        #print(row._fields)\n",
    "        measurement = {\n",
    "            'STATION_ID': getattr(row, 'STATION_ID'),\n",
    "            'MAC': getattr(row, 'MAC'),\n",
    "            'GEOHASH': getattr(row, 'GEOHASH'),\n",
    "            'PM25': getattr(row, 'PM25'),\n",
    "            'AQI': getattr(row, 'AQI'),\n",
    "            'TEMP': getattr(row, 'TEMP'),\n",
    "            'HUM': getattr(row, 'HUM'),\n",
    "            'CO2': getattr(row, 'CO2'),\n",
    "            'DATETIME': getattr(row, 'DATETIME'),\n",
    "        }\n",
    "        point = Point.from_dict(\n",
    "            measurement,\n",
    "            record_measurement_key=\"STATION_ID\",\n",
    "            record_time_key=\"DATETIME\",\n",
    "            record_tag_keys=[\"MAC\", \"GEOHASH\"],\n",
    "            record_field_keys=[\"PM25\", \"AQI\", \"TEMP\", \"HUM\", \"CO2\"]\n",
    "        )\n",
    "        #print('Point:', point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use RxPY to prepare batches for asyncio client\n",
    "# https://github.com/influxdata/influxdb-client-python/blob/master/examples/asynchronous_batching.py\n",
    "#\n",
    "# InfluxDBClientAsync\n",
    "#\n",
    "import asyncio\n",
    "from csv import DictReader\n",
    "\n",
    "import reactivex as rx\n",
    "from reactivex import operators as ops\n",
    "from reactivex.scheduler.eventloop import AsyncIOScheduler\n",
    "\n",
    "from influxdb_client import Point\n",
    "from influxdb_client.client.influxdb_client_async import InfluxDBClientAsync\n",
    "\n",
    "\n",
    "\n",
    "def station_measurements_to_generator(station_measurements):\n",
    "    \"\"\"\n",
    "    Parse your stations_measurements Data Frame into generator\n",
    "    \"\"\"\n",
    "    # For each station_measurements tuple\n",
    "    for row in station_measurements.itertuples():\n",
    "        #print(row._fields)\n",
    "        measurement = {\n",
    "            'MEASUREMENT_NAME': 'TANGARA_STATIONS',\n",
    "            'STATION_ID': getattr(row, 'STATION_ID'),\n",
    "            'MAC': getattr(row, 'MAC'),\n",
    "            'GEOHASH': getattr(row, 'GEOHASH'),\n",
    "            'PM25': getattr(row, 'PM25'),\n",
    "            'AQI': getattr(row, 'AQI'),\n",
    "            'TEMP': getattr(row, 'TEMP'),\n",
    "            'HUM': getattr(row, 'HUM'),\n",
    "            'CO2': getattr(row, 'CO2'),\n",
    "            'DATETIME': getattr(row, 'DATETIME'),\n",
    "        }\n",
    "        point = Point.from_dict(\n",
    "            measurement,\n",
    "            record_measurement_key=\"MEASUREMENT_NAME\",\n",
    "            record_time_key=\"DATETIME\",\n",
    "            record_tag_keys=[\"MAC\", \"GEOHASH\"],\n",
    "            record_field_keys=[\"PM25\", \"AQI\", \"TEMP\", \"HUM\", \"CO2\"]\n",
    "        )\n",
    "        #print('Point:', point)\n",
    "        yield point\n",
    "\n",
    "\n",
    "async def async_ingesting_stations_measurements(station_measurements):\n",
    "    # Check InfluxDB Version\n",
    "    if parameters['influxdb_version'] == '2.x':\n",
    "        # Secrets\n",
    "        # You can generate an API token from the \"API Tokens Tab\" in the UI\n",
    "        url = credentials['influxdb']['url']\n",
    "        token = credentials['influxdb']['token']\n",
    "        org = credentials['influxdb']['org']\n",
    "        bucket = credentials['influxdb']['bucket']\n",
    "    elif parameters['influxdb_version'] == '1.8':\n",
    "        # Secrets\n",
    "        url = credentials['influxdb']['url']\n",
    "        username = credentials['influxdb']['username']\n",
    "        password = credentials['influxdb']['password']\n",
    "        token = f'{username}:{password}'\n",
    "        database = credentials['influxdb']['database']\n",
    "        retention_policy = 'autogen'\n",
    "        bucket = f'{database}/{retention_policy}'\n",
    "        org = credentials['influxdb']['org']\n",
    "\n",
    "    # Async write batches\n",
    "    async with InfluxDBClientAsync(url=url, token=token, org=org) as client:\n",
    "        write_api = client.write_api()\n",
    "\n",
    "        \"\"\"\n",
    "        Async write\n",
    "        \"\"\"\n",
    "\n",
    "        async def async_write(batch):\n",
    "            \"\"\"\n",
    "            Prepare async task\n",
    "            \"\"\"\n",
    "            await write_api.write(bucket=bucket, record=batch)\n",
    "            return batch\n",
    "\n",
    "        \"\"\"\n",
    "        Prepare batches from generator\n",
    "        \"\"\"\n",
    "        batches = rx \\\n",
    "            .from_iterable(station_measurements_to_generator(station_measurements)) \\\n",
    "            .pipe(ops.buffer_with_count(500)) \\\n",
    "            .pipe(ops.map(lambda batch: rx.from_future(asyncio.ensure_future(async_write(batch)))), ops.merge_all())\n",
    "\n",
    "        done = asyncio.Future()\n",
    "\n",
    "        \"\"\"\n",
    "        Write batches by subscribing to Rx generator\n",
    "        \"\"\"\n",
    "        batches.subscribe(on_next=lambda batch: print(f'Written batch... {len(batch)}'),\n",
    "                        on_error=lambda ex: print(f'Unexpected error: {ex}'),\n",
    "                        on_completed=lambda: done.set_result(0),\n",
    "                        scheduler=AsyncIOScheduler(asyncio.get_event_loop()))\n",
    "        \"\"\"\n",
    "        Wait to finish all writes\n",
    "        \"\"\"\n",
    "        await done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#async_ingesting_stations_measurements(stations_measurements['TANGARA_FAC6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use RxPY to prepare batches for synchronous write into InfluxDB\n",
    "# https://github.com/influxdata/influxdb-client-python/blob/master/examples/import_data_set_sync_batching.py\n",
    "#\n",
    "# InfluxDBClientSync\n",
    "#\n",
    "from csv import DictReader\n",
    "\n",
    "import reactivex as rx\n",
    "from reactivex import operators as ops\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write.retry import WritesRetry\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "\n",
    "\n",
    "def station_measurements_to_generator(station_measurements):\n",
    "    \"\"\"\n",
    "    Parse your stations_measurements Data Frame into generator\n",
    "    \"\"\"\n",
    "    # For each station_measurements tuple\n",
    "    for row in station_measurements.itertuples():\n",
    "        #print(row._fields)\n",
    "        measurement = {\n",
    "            'MEASUREMENT_NAME': 'TANGARA_STATIONS',\n",
    "            'STATION_ID': getattr(row, 'STATION_ID'),\n",
    "            'MAC': getattr(row, 'MAC'),\n",
    "            'GEOHASH': getattr(row, 'GEOHASH'),\n",
    "            \"GEOREGION\": getattr(row, \"GEOREGION\"),\n",
    "            'PM25': getattr(row, 'PM25'),\n",
    "            'AQI': getattr(row, 'AQI'),\n",
    "            'TEMP': getattr(row, 'TEMP'),\n",
    "            'HUM': getattr(row, 'HUM'),\n",
    "            'CO2': getattr(row, 'CO2'),\n",
    "            'DATETIME': getattr(row, 'DATETIME'),\n",
    "        }\n",
    "        point = Point.from_dict(\n",
    "            measurement,\n",
    "            record_measurement_key=\"MEASUREMENT_NAME\",\n",
    "            record_time_key=\"DATETIME\",\n",
    "            record_tag_keys=[\"STATION_ID\", \"MAC\", \"GEOHASH\", \"GEOREGION\"],\n",
    "            record_field_keys=[\"PM25\", \"AQI\", \"TEMP\", \"HUM\", \"CO2\", \"STATION_ID\", \"MAC\", \"GEOHASH\"]\n",
    "        )\n",
    "        #print('Point:', point)\n",
    "        yield point\n",
    "\n",
    "\n",
    "def sync_ingesting_stations_measurements(station_measurements):\n",
    "    # Check InfluxDB Version\n",
    "    if parameters['influxdb_version'] == '2.x':\n",
    "        # Secrets\n",
    "        # You can generate an API token from the \"API Tokens Tab\" in the UI\n",
    "        url = credentials['influxdb']['url']\n",
    "        token = credentials['influxdb']['token']\n",
    "        org = credentials['influxdb']['org']\n",
    "        bucket = credentials['influxdb']['bucket']\n",
    "    elif parameters['influxdb_version'] == '1.8':\n",
    "        # Secrets\n",
    "        url = credentials['influxdb']['url']\n",
    "        username = credentials['influxdb']['username']\n",
    "        password = credentials['influxdb']['password']\n",
    "        token = f'{username}:{password}'\n",
    "        database = credentials['influxdb']['database']\n",
    "        retention_policy = 'autogen'\n",
    "        bucket = f'{database}/{retention_policy}'\n",
    "        org = credentials['influxdb']['org']\n",
    "\n",
    "    \"\"\"\n",
    "    Define Retry strategy - 3 attempts => 2, 4, 8\n",
    "    \"\"\"\n",
    "    retries = WritesRetry(total=3, retry_interval=1, exponential_base=2)\n",
    "    with InfluxDBClient(url=url, token=token, org=org, retries=retries) as client:\n",
    "\n",
    "        \"\"\"\n",
    "        Use synchronous version of WriteApi to strongly depends on result of write\n",
    "        \"\"\"\n",
    "        write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "        \"\"\"\n",
    "        Prepare batches from generator\n",
    "        \"\"\"\n",
    "        batches = rx \\\n",
    "            .from_iterable(station_measurements_to_generator(station_measurements)) \\\n",
    "            .pipe(ops.buffer_with_count(500))\n",
    "\n",
    "\n",
    "        def write_batch(batch):\n",
    "            \"\"\"\n",
    "            Synchronous write\n",
    "            \"\"\"\n",
    "            print(f'Writing... {len(batch)}')\n",
    "            write_api.write(bucket=bucket, record=batch)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Write batches\n",
    "        \"\"\"\n",
    "        batches.subscribe(on_next=lambda batch: write_batch(batch),\n",
    "                        on_error=lambda ex: print(f'Unexpected error: {ex}'),\n",
    "                        on_completed=lambda: print('Import finished!'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_ingesting_stations_measurements(stations_measurements['TANGARA_F1AE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_ingesting_stations_measurements(stations_measurements['TANGARA_EA06'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_ingesting_stations_measurements(stations_measurements['TANGARA_FAC6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, station_measurements in stations_measurements.items():\n",
    "    print(station_id)\n",
    "    sync_ingesting_stations_measurements(station_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import json\n",
    "def get_json(entrada):\n",
    "    for station_id, station_measurements in entrada.items():\n",
    "        print(station_id)\n",
    "        entrada[station_id] = station_measurements.to_json()\n",
    "    return entrada\n",
    "\n",
    "salida = get_json(stations_measurements.copy())\n",
    "print(type(salida))\n",
    "print(type(json.dumps(salida, indent = 3)))\n",
    "#print('salida', salida)\n",
    "#json.dumps(salida)\n",
    "\"\"\"\n",
    "# Save stations_measurements into Catalog\n",
    "catalog.save('stations_measurements', stations_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (tangara_pipeline)",
   "language": "python",
   "name": "kedro_tangara_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
